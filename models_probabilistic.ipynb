{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T09:48:24.379021Z",
     "start_time": "2024-11-10T09:48:24.373825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "from nacl.pwhash.argon2i import verify\n",
    "from sympy.solvers.diophantine.diophantine import Linear\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from io import StringIO\n",
    "rng = np.random.RandomState(42)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import TreeSearch, BayesianEstimator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import ast\n",
    "import ast"
   ],
   "id": "a4fc8b7403cab8c1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T09:23:49.884396Z",
     "start_time": "2024-11-10T09:23:49.372216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"csv/outlier_filtered.csv\")\n",
    "\n",
    "response_var = 'Diabetes_012'\n",
    "features = list(df.columns)\n",
    "features.remove(response_var)\n",
    "\n",
    "print(features, response_var)\n",
    "# Pretty-print using tabulate\n",
    "df.head(1)"
   ],
   "id": "f7c58e6c0fa597d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BMI_q_normal', 'MentHlth', 'PhysHlth_q_uniform', 'GenHlth_q_uniform', 'Age_q_uniform', 'Education_coxbox', 'Income_q_uniform', 'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex'] Diabetes_012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   BMI_q_normal  MentHlth  PhysHlth_q_uniform  GenHlth_q_uniform  \\\n",
       "0       1.60221  1.998592            0.891892                1.0   \n",
       "\n",
       "   Age_q_uniform  Education_coxbox  Income_q_uniform  Diabetes_012  HighBP  \\\n",
       "0       0.581582         -1.109347          0.117117           0.0     1.0   \n",
       "\n",
       "   HighChol  ...  Stroke  HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  \\\n",
       "0       1.0  ...     0.0                   0.0           0.0     0.0      1.0   \n",
       "\n",
       "   HvyAlcoholConsump  AnyHealthcare  NoDocbcCost  DiffWalk  Sex  \n",
       "0                0.0            1.0          0.0       1.0  0.0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI_q_normal</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth_q_uniform</th>\n",
       "      <th>GenHlth_q_uniform</th>\n",
       "      <th>Age_q_uniform</th>\n",
       "      <th>Education_coxbox</th>\n",
       "      <th>Income_q_uniform</th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>...</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.60221</td>\n",
       "      <td>1.998592</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581582</td>\n",
       "      <td>-1.109347</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-10T16:30:03.070441Z",
     "start_time": "2024-11-10T16:30:03.050975Z"
    }
   },
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "models = {\n",
    "    'Logistic regression': BayesSearchCV(\n",
    "        LogisticRegression(solver='newton-cholesky'),\n",
    "        {\n",
    "            'penalty': Categorical(['l2', None]),\n",
    "            'C': Real(0.001, 100, prior='log-uniform'),\n",
    "            'class_weight': Categorical(['balanced', None])\n",
    "        },\n",
    "        random_state=rng,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        n_points=5,\n",
    "        n_iter=50\n",
    "    ),\n",
    "    \n",
    "    # Discriminant Analysis\n",
    "    'Discriminant analysis (not svd)': BayesSearchCV(\n",
    "        LinearDiscriminantAnalysis(),\n",
    "        {\n",
    "            'solver': Categorical(['lsqr', 'eigen']),\n",
    "            'shrinkage': Real(0.0001, 1.0, prior='uniform'),\n",
    "            'tol': Real(1e-5, 1.0, prior='uniform'),\n",
    "        },\n",
    "        random_state=rng,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        n_points=4,\n",
    "        n_iter=50\n",
    "    ),\n",
    "    # Discriminant Analysis\n",
    "    'Discriminant analysis (svd)': BayesSearchCV(\n",
    "        LinearDiscriminantAnalysis(store_covariance=True),\n",
    "        {\n",
    "            'tol': Real(1e-5, 1.0, prior='uniform'),\n",
    "        },\n",
    "        random_state=rng,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        n_points=4,\n",
    "        n_iter=50\n",
    "    ),\n",
    "    'QuadraticDiscriminantAnalysis': BayesSearchCV(\n",
    "        QuadraticDiscriminantAnalysis(),\n",
    "        {\n",
    "            'reg_param': Real(0.0001, 1.0, prior='uniform'),  # Regularization parameter\n",
    "            'tol': Real(1e-5, 1.0, prior='uniform'),          # Tolerance for convergence\n",
    "        },\n",
    "        random_state=rng,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        n_points=4,\n",
    "        n_iter=50\n",
    "    ),\n",
    "  'GradientBoostingClassifier': BayesSearchCV(\n",
    "         GradientBoostingClassifier(random_state=rng),\n",
    "        {\n",
    "            'n_estimators': Integer(50, 200),  # Number of boosting stages (trees)\n",
    "            'learning_rate': Real(0.01, 0.3, prior='uniform'),  # Learning rate\n",
    "            'max_depth': Integer(3, 10),  # Maximum depth of individual estimators\n",
    "            'min_samples_split': Integer(2, 10),  # Minimum number of samples required to split an internal node\n",
    "            'subsample': Real(0.5, 1.0, prior='uniform'),  # Fraction of samples used for fitting each base learner\n",
    "        },\n",
    "        random_state=42,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        n_iter=4,\n",
    "        n_points=3\n",
    "    ),\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:30:03.818031Z",
     "start_time": "2024-11-10T16:30:03.693093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = df[features], df[response_var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.9,\n",
    "                                                    random_state=rng,\n",
    "                                                    stratify=y)\n",
    "\n",
    "fea_subsets = {\n",
    "    8:[0, 3, 4, 6, 7, 8, 12, 16],\n",
    "    10:[0, 3, 4, 6, 7, 8, 9, 12, 16, 20],\n",
    "    12:[0, 3, 4, 6, 7, 8, 9, 11, 12, 16, 17, 19],\n",
    "    14:[0, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19],\n",
    "    16:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 1]\n",
    "}\n"
   ],
   "id": "1596b57a39170a1f",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:30:05.265856Z",
     "start_time": "2024-11-10T16:30:05.263572Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f5e3b68f72fdddb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T18:35:12.557889Z",
     "start_time": "2024-11-10T16:30:06.170596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start tracking total runtime\n",
    "def run_models(elapse=0, skip=[]):\n",
    "    start_total = time.time()\n",
    "    \n",
    "    y = y_train\n",
    "    it = 0\n",
    "    \n",
    "    for model in models.keys():\n",
    "        if model not in ['GradientBoostingClassifier']:\n",
    "            continue \n",
    "            \n",
    "        for k in fea_subsets.keys():\n",
    "            if it <= elapse or model in skip:\n",
    "                print(f\"Skipping it={it} with {model};{k};\")\n",
    "                it += 1\n",
    "                continue \n",
    "                \n",
    "            # Start tracking time for this iteration\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Define the feature subset and input data\n",
    "            fea_subset = np.array(features)[fea_subsets[k]]\n",
    "            X = X_train[fea_subset]\n",
    "            \n",
    "            # Fit the model\n",
    "            bayes_search = models[model]\n",
    "            \n",
    "            \n",
    "            print(f\"\\rFitting {model}...                   \", end=\"\")\n",
    "            if model == 'ComplementNB':\n",
    "                X_scaled = MinMaxScaler().fit_transform(X)\n",
    "                bayes_search.fit(X_scaled, y)  # Fit the model on the transformed data\n",
    "            else:\n",
    "                bayes_search.fit(X, y) \n",
    "            print(f\"\\rFitting {model} completed            \", end=\"\")\n",
    "            \n",
    "            \n",
    "            # Get best parameters and score\n",
    "            best_params = bayes_search.best_params_\n",
    "            score = bayes_search.score(X_test[fea_subset], y_test)\n",
    "            \n",
    "            # Calculate elapsed time for this iteration\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Print results along with time taken\n",
    "            print(f\"\\r{it};{model};{k};{best_params};{score:01.04f};{elapsed_time:06.02f}\")\n",
    "            it += 1\n",
    "    \n",
    "    # Calculate and print total runtime\n",
    "    total_time = time.time() - start_total\n",
    "    print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "\n",
    "run_models(-1)"
   ],
   "id": "5cebee864b8ce9dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0;GradientBoostingClassifier;8;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.3970;1788.74\n",
      "1;GradientBoostingClassifier;10;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.3972;1333.72\n",
      "2;GradientBoostingClassifier;12;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.4022;1343.06\n",
      "3;GradientBoostingClassifier;14;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.4033;1474.30\n",
      "4;GradientBoostingClassifier;16;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.4023;1566.56\n",
      "Total runtime: 7506.38 seconds\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T19:04:27.301383Z",
     "start_time": "2024-11-10T19:04:27.285612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = \"\"\"\n",
    "it;model;num fea;best parameters;score;elapsed time \n",
    "0;Logistic regression;8;OrderedDict({'C': 0.009275062636581224, 'class_weight': 'balanced', 'penalty': 'l2'});0.4428;073.66\n",
    "1;Logistic regression;10;OrderedDict({'C': 0.019884322615837377, 'class_weight': 'balanced', 'penalty': 'l2'});0.4421;073.19\n",
    "2;Logistic regression;12;OrderedDict({'C': 0.0014661424746571484, 'class_weight': 'balanced', 'penalty': 'l2'});0.4420;081.25\n",
    "3;Logistic regression;14;OrderedDict({'C': 0.0049931659015543745, 'class_weight': 'balanced', 'penalty': 'l2'});0.4424;097.71\n",
    "4;Logistic regression;16;OrderedDict({'C': 0.008986806532830008, 'class_weight': 'balanced', 'penalty': 'l2'});0.4434;133.19\n",
    "5;Discriminant analysis (not svd);8;OrderedDict({'shrinkage': 0.7753069475939367, 'solver': 'eigen', 'tol': 1.0});0.4343;038.70\n",
    "6;Discriminant analysis (not svd);10;OrderedDict({'shrinkage': 0.7516415380327516, 'solver': 'lsqr', 'tol': 1e-05});0.4365;037.12\n",
    "7;Discriminant analysis (not svd);12;OrderedDict({'shrinkage': 0.7709731236105747, 'solver': 'lsqr', 'tol': 1e-05});0.4437;026.60\n",
    "8;Discriminant analysis (not svd);14;OrderedDict({'shrinkage': 0.7385508959093038, 'solver': 'lsqr', 'tol': 1e-05});0.4399;033.46\n",
    "9;Discriminant analysis (not svd);16;OrderedDict({'shrinkage': 0.7820175034407315, 'solver': 'lsqr', 'tol': 1e-05});0.4283;048.99\n",
    "10;Discriminant analysis (svd);8;OrderedDict({'tol': 0.8787898063269084});0.3933;029.79\n",
    "11;Discriminant analysis (svd);10;OrderedDict({'tol': 0.8007791561388778});0.3934;044.66\n",
    "12;Discriminant analysis (svd);12;OrderedDict({'tol': 0.881514287541885});0.4077;036.27\n",
    "13;Discriminant analysis (svd);14;OrderedDict({'tol': 0.8682414474458714});0.4080;051.64\n",
    "14;Discriminant analysis (svd);16;OrderedDict({'tol': 0.8804868604416194});0.3986;050.19\n",
    "15;ComplementNB;8;OrderedDict({'alpha': 9.83097052187787, 'fit_prior': True, 'force_alpha': False, 'norm': False});0.3544;019.80\n",
    "16;ComplementNB;10;OrderedDict({'alpha': 10.0, 'fit_prior': False, 'force_alpha': False, 'norm': False});0.3820;020.02\n",
    "17;ComplementNB;12;OrderedDict({'alpha': 9.728726870982992, 'fit_prior': True, 'force_alpha': True, 'norm': True});0.3965;020.74\n",
    "18;ComplementNB;14;OrderedDict({'alpha': 10.0, 'fit_prior': True, 'force_alpha': True, 'norm': True});0.4114;021.65\n",
    "19;ComplementNB;16;OrderedDict({'alpha': 9.955213218146183, 'fit_prior': True, 'force_alpha': True, 'norm': True});0.4058;020.61\n",
    "0;QuadraticDiscriminantAnalysis;8;OrderedDict({'reg_param': 0.0001, 'tol': 1e-05});0.4208;032.06\n",
    "1;QuadraticDiscriminantAnalysis;10;OrderedDict({'reg_param': 0.003149940162422831, 'tol': 0.0029025043785303713});0.4409;032.99\n",
    "2;QuadraticDiscriminantAnalysis;12;OrderedDict({'reg_param': 0.0001, 'tol': 0.8165426531203231});0.4290;039.92\n",
    "3;QuadraticDiscriminantAnalysis;14;OrderedDict({'reg_param': 0.00029860625576866914, 'tol': 0.0848853341071096});0.4284;042.26\n",
    "4;QuadraticDiscriminantAnalysis;16;OrderedDict({'reg_param': 0.0001, 'tol': 1.0});0.4330;050.90\n",
    "0;GradientBoostingClassifier;8;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.3970;1788.74\n",
    "1;GradientBoostingClassifier;10;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.3972;1333.72\n",
    "2;GradientBoostingClassifier;12;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.4022;1343.06\n",
    "3;GradientBoostingClassifier;14;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.4033;1474.30\n",
    "4;GradientBoostingClassifier;16;OrderedDict({'learning_rate': 0.25284262311045247, 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 193, 'subsample': 0.9320639577324754});0.4023;1566.56\n",
    "\"\"\"\n",
    "\n",
    "stats = pd.read_csv(StringIO(output), delimiter=\";\")\n",
    "print(stats.columns)\n",
    "best_models = stats.loc[stats.groupby('model')['score'].idxmax()]\n",
    "best_models"
   ],
   "id": "31287beca06e1636",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['it', 'model', 'num fea', 'best parameters', 'score', 'elapsed time '], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    it                            model  num fea  \\\n",
       "18  18                     ComplementNB       14   \n",
       "7    7  Discriminant analysis (not svd)       12   \n",
       "13  13      Discriminant analysis (svd)       14   \n",
       "28   3       GradientBoostingClassifier       14   \n",
       "4    4              Logistic regression       16   \n",
       "21   1    QuadraticDiscriminantAnalysis       10   \n",
       "\n",
       "                                      best parameters   score  elapsed time   \n",
       "18  OrderedDict({'alpha': 10.0, 'fit_prior': True,...  0.4114          21.65  \n",
       "7   OrderedDict({'shrinkage': 0.7709731236105747, ...  0.4437          26.60  \n",
       "13           OrderedDict({'tol': 0.8682414474458714})  0.4080          51.64  \n",
       "28  OrderedDict({'learning_rate': 0.25284262311045...  0.4033        1474.30  \n",
       "4   OrderedDict({'C': 0.008986806532830008, 'class...  0.4434         133.19  \n",
       "21  OrderedDict({'reg_param': 0.003149940162422831...  0.4409          32.99  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>it</th>\n",
       "      <th>model</th>\n",
       "      <th>num fea</th>\n",
       "      <th>best parameters</th>\n",
       "      <th>score</th>\n",
       "      <th>elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>14</td>\n",
       "      <td>OrderedDict({'alpha': 10.0, 'fit_prior': True,...</td>\n",
       "      <td>0.4114</td>\n",
       "      <td>21.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Discriminant analysis (not svd)</td>\n",
       "      <td>12</td>\n",
       "      <td>OrderedDict({'shrinkage': 0.7709731236105747, ...</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>26.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Discriminant analysis (svd)</td>\n",
       "      <td>14</td>\n",
       "      <td>OrderedDict({'tol': 0.8682414474458714})</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>51.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>14</td>\n",
       "      <td>OrderedDict({'learning_rate': 0.25284262311045...</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>1474.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>16</td>\n",
       "      <td>OrderedDict({'C': 0.008986806532830008, 'class...</td>\n",
       "      <td>0.4434</td>\n",
       "      <td>133.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>10</td>\n",
       "      <td>OrderedDict({'reg_param': 0.003149940162422831...</td>\n",
       "      <td>0.4409</td>\n",
       "      <td>32.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T10:26:32.228217Z",
     "start_time": "2024-11-10T10:15:08.137825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import bnlearn as bn\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import f1_score\n",
    "# \n",
    "# # Define the target or class variable\n",
    "# class_node = response_var\n",
    "# \n",
    "# # Initialize a dictionary to store model performance\n",
    "# root_nodes = [col for col in df.columns if col != class_node]\n",
    "# model_scores = {}\n",
    "# \n",
    "# \n",
    "# # Validation set for scoring\n",
    "# df_test = pd.concat([X_test, y_test.rename(class_node)], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "for k in fea_subsets.keys():\n",
    "    if k < 16:\n",
    "        continue \n",
    "    \n",
    "    if k != 16: # pgmpy has an error when the number of features is 16. Unknown reason\n",
    "        fea_subset = np.array(features)[fea_subsets[k]]\n",
    "    else:\n",
    "        fea_subset = features\n",
    "        \n",
    "    for root_node in fea_subset:\n",
    "        df_train = pd.concat([X_train[fea_subset], y_train.rename(response_var)], axis=1)\n",
    "        # df_train = pd.DataFrame(np.concatenate((y_train, X_train), axis=1), columns=[response_var] + features)\n",
    "        \n",
    "        # Learn the TAN structure from the data\n",
    "        # Choose a random feature as the root node\n",
    "        estimator = TreeSearch(df_train, root_node=root_node)\n",
    "        dag = estimator.estimate(estimator_type='tan', class_node=response_var)\n",
    "        \n",
    "        # Construct Bayesian Network from the learned structure\n",
    "        model = BayesianNetwork(dag.edges())\n",
    "        \n",
    "        # Parameterize the model using the training data\n",
    "        model.fit(df_train, estimator=BayesianEstimator, prior_type='K2')\n",
    "        \n",
    "        # Make predictions on the test set using the trained TAN model\n",
    "        X_test_df = pd.DataFrame(X_test, columns=features)\n",
    "        y_pred = model.predict(X_test_df[fea_subset]).values\n",
    "        \n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        accuracy_per_class = matrix.diagonal() / matrix.sum(axis=1)\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        precision = precision_score(y_test, y_pred, average='macro')\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        print(f\"TAN,{k},{accuracy:.03f},{\",\".join(f\"{x:.3f}\" for x in accuracy_per_class)},{f1_macro:.03f},{precision:.03f},{recall:.03f},{root_node}\")\n",
    "        "
   ],
   "id": "db950dfb50b4ef26",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1de808eb5c74558b20aa8e2959c69fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "964d25c60b0e47dc809f8b36b78e8ad9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.393,0.440,0.443,0.439,BMI_q_normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2cf15322f6f4f72967bf76a239d2372"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "185d722c36d04ebb857a439d642fa3ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,MentHlth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4bbdf58055e24393a9c01c008ea73663"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab5a328989b64251a4c8edcb9802ca33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,PhysHlth_q_uniform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7f959fbf95f4ff6930fc0652dfe1e7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0c52b5c97ca4e9582ddb45aa023a7bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,GenHlth_q_uniform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1747a038c20249619add952eff576c3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66893c7263fd47799e7e77161fca22bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,Age_q_uniform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd825d4f3ab547918b07676872dd53d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd675ae815ff4fa58a55502c9d37b186"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,Education_coxbox\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b71db404d09a4f0480abcf129d45fb39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05bdd827124044e799c97330f0e51cd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,Income_q_uniform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24c662d1e5694ff4955ddeb8edfa5105"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23e6e0b92db74e0082b2c015cce10f4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,HighBP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63e327057c0a4e20a427464530e0adbf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2875705a23c942e28b1274c79789594a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,HighChol\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e772b79fa0a43b5b5d891aad50fe802"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a932c20f22e4f4298eeb1d8f81727d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,CholCheck\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db84419b193c4c4e9ac14c5832319503"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6dff03ef4e141d488d8356f5e09de0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,Smoker\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fa91cb3909f41409aa82891e9f5c5f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20ba4c52314d424bbcbdfafd6824f82e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,Stroke\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e8e1e4272914a039783be6bed9699d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e479636420334a378e1a767a796d40f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,HeartDiseaseorAttack\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d336dcadc5ce4e32a62216856827da32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d67b70f746c24ff5b4543bf2eadd2f1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,PhysActivity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da44e800a328499692da6e0d74710afe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4323bd3c12704a32b44e4bd3fb47b361"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.393,0.441,0.443,0.439,Fruits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04e40c5adcf943a5940bb012da1ea65a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2af5e42486a7428cb0ff8cde3b99f0ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.393,0.441,0.443,0.439,Veggies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86d91315b4f34f678637c10aad69e162"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b9581420e634abeb689362f243ba88a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,HvyAlcoholConsump\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e60582f245c45fb9d94bb9fbaa90521"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e4dbb6cab7c402eae7143fbe417d8b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,AnyHealthcare\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2cfcb7066564a5680b71f4ec4b8bf10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e21366237964556a8f15616d3ea516a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,NoDocbcCost\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7a80e4b62e64efea405db29aacc61de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e80a563607e4a20bf9a875503e9fdfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,DiffWalk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Building tree:   0%|          | 0/231.0 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1517b5656a4c4b20a1d95d19b6e31a6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/24703 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98bf09b4a2ac45aa9d358a7ee14efe61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN,16,0.832,0.923,0.000,0.393,0.440,0.443,0.439,Sex\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T10:27:28.789553Z",
     "start_time": "2024-11-10T10:27:28.770820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = \"\"\"\n",
    "model,num fea,accuracy,accuracy 0,accuracy 1,accuracy 2,f1 macro,precision,recall,root node\n",
    "TAN,8,0.837,0.938,0.000,0.336,0.432,0.445,0.425,BMI_q_normal\n",
    "TAN,8,0.837,0.938,0.000,0.336,0.432,0.445,0.425,GenHlth_q_uniform\n",
    "TAN,8,0.837,0.938,0.000,0.336,0.432,0.445,0.425,Age_q_uniform\n",
    "TAN,8,0.837,0.938,0.000,0.336,0.432,0.445,0.425,Income_q_uniform\n",
    "TAN,8,0.837,0.938,0.000,0.336,0.432,0.445,0.425,HighBP\n",
    "TAN,8,0.837,0.938,0.000,0.336,0.432,0.445,0.425,HighChol\n",
    "TAN,8,0.837,0.938,0.000,0.336,0.432,0.445,0.425,HeartDiseaseorAttack\n",
    "TAN,8,0.837,0.938,0.000,0.336,0.432,0.445,0.425,HvyAlcoholConsump\n",
    "TAN,10,0.836,0.936,0.000,0.346,0.433,0.445,0.427,BMI_q_normal\n",
    "TAN,10,0.837,0.936,0.000,0.347,0.434,0.446,0.428,GenHlth_q_uniform\n",
    "TAN,10,0.837,0.936,0.000,0.347,0.434,0.446,0.428,Age_q_uniform\n",
    "TAN,10,0.837,0.936,0.000,0.347,0.434,0.446,0.428,Income_q_uniform\n",
    "TAN,10,0.837,0.936,0.000,0.347,0.434,0.446,0.428,HighBP\n",
    "TAN,10,0.837,0.936,0.000,0.347,0.434,0.446,0.428,HighChol\n",
    "TAN,10,0.837,0.936,0.000,0.347,0.434,0.446,0.428,CholCheck\n",
    "TAN,10,0.837,0.936,0.000,0.347,0.434,0.446,0.428,HeartDiseaseorAttack\n",
    "TAN,10,0.836,0.936,0.000,0.346,0.433,0.445,0.427,HvyAlcoholConsump\n",
    "TAN,10,0.837,0.936,0.000,0.346,0.434,0.446,0.427,Sex\n",
    "TAN,12,0.835,0.931,0.000,0.367,0.437,0.445,0.433,BMI_q_normal\n",
    "TAN,12,0.835,0.931,0.002,0.367,0.439,0.556,0.433,GenHlth_q_uniform\n",
    "TAN,12,0.835,0.931,0.002,0.366,0.439,0.556,0.433,Age_q_uniform\n",
    "TAN,12,0.835,0.931,0.002,0.366,0.439,0.556,0.433,Income_q_uniform\n",
    "TAN,12,0.835,0.931,0.002,0.366,0.439,0.556,0.433,HighBP\n",
    "TAN,12,0.835,0.931,0.002,0.366,0.439,0.556,0.433,HighChol\n",
    "TAN,12,0.835,0.931,0.002,0.366,0.439,0.556,0.433,CholCheck\n",
    "TAN,12,0.835,0.931,0.002,0.367,0.439,0.556,0.433,Stroke\n",
    "TAN,12,0.835,0.931,0.002,0.366,0.439,0.556,0.433,HeartDiseaseorAttack\n",
    "TAN,12,0.835,0.931,0.000,0.367,0.437,0.445,0.433,HvyAlcoholConsump\n",
    "TAN,12,0.835,0.931,0.002,0.366,0.439,0.556,0.433,AnyHealthcare\n",
    "TAN,12,0.835,0.931,0.002,0.366,0.439,0.556,0.433,DiffWalk\n",
    "TAN,14,0.834,0.927,0.000,0.378,0.438,0.444,0.435,BMI_q_normal\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,GenHlth_q_uniform\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,Age_q_uniform\n",
    "TAN,14,0.834,0.928,0.002,0.377,0.440,0.611,0.436,Education_coxbox\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,Income_q_uniform\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,HighBP\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,HighChol\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,CholCheck\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,Stroke\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,HeartDiseaseorAttack\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,PhysActivity\n",
    "TAN,14,0.834,0.927,0.000,0.377,0.438,0.444,0.435,HvyAlcoholConsump\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,AnyHealthcare\n",
    "TAN,14,0.834,0.928,0.002,0.378,0.440,0.611,0.436,DiffWalk\n",
    "TAN,16,0.832,0.923,0.000,0.393,0.440,0.443,0.439,BMI_q_normal\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,MentHlth\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,PhysHlth_q_uniform\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,GenHlth_q_uniform\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,Age_q_uniform\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,Education_coxbox\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,Income_q_uniform\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,HighBP\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,HighChol\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,CholCheck\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,Smoker\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,Stroke\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,HeartDiseaseorAttack\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,PhysActivity\n",
    "TAN,16,0.832,0.923,0.000,0.393,0.441,0.443,0.439,Fruits\n",
    "TAN,16,0.832,0.923,0.000,0.393,0.441,0.443,0.439,Veggies\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,HvyAlcoholConsump\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,AnyHealthcare\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.443,0.439,NoDocbcCost\n",
    "TAN,16,0.832,0.923,0.000,0.394,0.441,0.444,0.439,DiffWalk\n",
    "TAN,16,0.832,0.923,0.000,0.393,0.440,0.443,0.439,Sex\n",
    "\"\"\"\n",
    "\n",
    "stats = pd.read_csv(StringIO(output), delimiter=\",\")\n",
    "best_tan_models = stats.loc[stats.groupby('num fea')['f1 macro'].idxmax()]\n",
    "best_tan_models"
   ],
   "id": "ad8c6e54855b815c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   model  num fea  accuracy  accuracy 0  accuracy 1  accuracy 2  f1 macro  \\\n",
       "0    TAN        8     0.837       0.938       0.000       0.336     0.432   \n",
       "9    TAN       10     0.837       0.936       0.000       0.347     0.434   \n",
       "19   TAN       12     0.835       0.931       0.002       0.367     0.439   \n",
       "31   TAN       14     0.834       0.928       0.002       0.378     0.440   \n",
       "45   TAN       16     0.832       0.923       0.000       0.394     0.441   \n",
       "\n",
       "    precision  recall          root node  \n",
       "0       0.445   0.425       BMI_q_normal  \n",
       "9       0.446   0.428  GenHlth_q_uniform  \n",
       "19      0.556   0.433  GenHlth_q_uniform  \n",
       "31      0.611   0.436  GenHlth_q_uniform  \n",
       "45      0.443   0.439           MentHlth  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>num fea</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy 0</th>\n",
       "      <th>accuracy 1</th>\n",
       "      <th>accuracy 2</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>root node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.425</td>\n",
       "      <td>BMI_q_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.428</td>\n",
       "      <td>GenHlth_q_uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TAN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.433</td>\n",
       "      <td>GenHlth_q_uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TAN</td>\n",
       "      <td>14</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.436</td>\n",
       "      <td>GenHlth_q_uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TAN</td>\n",
       "      <td>16</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.439</td>\n",
       "      <td>MentHlth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T19:10:33.300014Z",
     "start_time": "2024-11-10T19:08:00.730578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# print(best_models)\n",
    "print(\"model,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\")\n",
    "for index, row in best_models.iterrows():\n",
    "    model_name = row['model']\n",
    "    if model_name != \"GradientBoostingClassifier\":\n",
    "        continue \n",
    "    print(row)\n",
    "    \n",
    "    subset_features = np.array(features)[fea_subsets[int(row['num fea'])]]\n",
    "    kwargs = row['best parameters'].replace(\"OrderedDict(\", '').replace(\"})\", '}')\n",
    "    kwargs = ast.literal_eval(kwargs)\n",
    "    if model_name == 'Logistic regression': \n",
    "        model = LogisticRegression(solver='newton-cholesky', **kwargs)\n",
    "    elif model_name == 'Discriminant analysis (not svd)': \n",
    "        model = LinearDiscriminantAnalysis(**kwargs)\n",
    "    elif model_name == 'Discriminant analysis (svd)': \n",
    "        model = LinearDiscriminantAnalysis(store_covariance=True, **kwargs)\n",
    "    elif model_name == 'ComplementNB': \n",
    "        model = ComplementNB(**kwargs)\n",
    "    elif model_name == 'QuadraticDiscriminantAnalysis': \n",
    "        model = QuadraticDiscriminantAnalysis(**kwargs)\n",
    "    elif model_name == \"GradientBoostingClassifier\":\n",
    "        model = GradientBoostingClassifier()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)  # You can adjust n_splits as needed\n",
    "    accuracies = []\n",
    "    f1_macros = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    accuracies_per_class = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_index], y_train.iloc[test_index]\n",
    "        \n",
    "        if model_name == 'ComplementNB':\n",
    "            mmt = MinMaxScaler()\n",
    "            X_train_fold = mmt.fit_transform(X_train_fold)\n",
    "            X_test_fold = mmt.transform(X_test_fold)  # Apply the same scaler for test fold\n",
    "            model.fit(X_train_fold[subset_features], y_train_fold)  # Fit the model on the transformed data\n",
    "        else:\n",
    "            model.fit(X_train_fold[subset_features], y_train_fold) \n",
    "        \n",
    "        y_pred = model.predict(X_test_fold[subset_features])\n",
    "        \n",
    "        # Calculate the metrics\n",
    "        accuracy = accuracy_score(y_test_fold, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        matrix = confusion_matrix(y_test_fold, y_pred)\n",
    "        accuracy_per_class = matrix.diagonal() / matrix.sum(axis=1)\n",
    "        accuracies_per_class.append(accuracy_per_class)\n",
    "        \n",
    "        f1_macro = f1_score(y_test_fold, y_pred, average='macro')\n",
    "        f1_macros.append(f1_macro)\n",
    "        \n",
    "        precision = precision_score(y_test_fold, y_pred, average='macro')\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test_fold, y_pred, average='macro')\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"{model_name},{np.mean(accuracies):.03f},{\",\".join(f\"{x:.3f}\" for x in np.mean(accuracies_per_class, axis=0))},{np.mean(f1_macros):.03f},{np.mean(precisions):.03f},{np.mean(recalls):.03f}\")\n",
    "    "
   ],
   "id": "7007a66df3fe71f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\n",
      "it                                                                 3\n",
      "model                                     GradientBoostingClassifier\n",
      "num fea                                                           14\n",
      "best parameters    OrderedDict({'learning_rate': 0.25284262311045...\n",
      "score                                                         0.4033\n",
      "elapsed time                                                  1474.3\n",
      "Name: 28, dtype: object\n",
      "GradientBoostingClassifier,0.850,0.977,0.000,0.192,0.401,0.473,0.390\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T10:32:49.449643Z",
     "start_time": "2024-11-10T10:32:49.435940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = \"\"\"model,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\n",
    "ComplementNB,0.790,0.885,0.091,0.305,0.425,0.433,0.427\n",
    "Discriminant analysis (not svd),0.818,0.900,0.000,0.430,0.437,0.431,0.443\n",
    "Discriminant analysis (svd),0.845,0.968,0.000,0.212,0.405,0.458,0.393\n",
    "Logistic regression,0.687,0.700,0.167,0.678,0.436,0.438,0.515\n",
    "QuadraticDiscriminantAnalysis,0.772,0.830,0.010,0.521,0.428,0.424,0.454\n",
    "TAN,0.832,0.923,0.000,0.394,0.441,0.443,0.439\n",
    "\"\"\"\n",
    "stats = pd.read_csv(StringIO(output), delimiter=\",\")\n",
    "stats"
   ],
   "id": "11d24b51e6f72c8b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             model  accuracy  accuracy 0  accuracy 1  \\\n",
       "0                     ComplementNB     0.790       0.885       0.091   \n",
       "1  Discriminant analysis (not svd)     0.818       0.900       0.000   \n",
       "2      Discriminant analysis (svd)     0.845       0.968       0.000   \n",
       "3              Logistic regression     0.687       0.700       0.167   \n",
       "4    QuadraticDiscriminantAnalysis     0.772       0.830       0.010   \n",
       "5                              TAN     0.832       0.923       0.000   \n",
       "\n",
       "   accuracy 2  f1_macro  precision  recall  \n",
       "0       0.305     0.425      0.433   0.427  \n",
       "1       0.430     0.437      0.431   0.443  \n",
       "2       0.212     0.405      0.458   0.393  \n",
       "3       0.678     0.436      0.438   0.515  \n",
       "4       0.521     0.428      0.424   0.454  \n",
       "5       0.394     0.441      0.443   0.439  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy 0</th>\n",
       "      <th>accuracy 1</th>\n",
       "      <th>accuracy 2</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discriminant analysis (not svd)</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discriminant analysis (svd)</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TAN</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a28b5cd8e75ca5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T19:13:04.362469Z",
     "start_time": "2024-11-10T19:10:33.308298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import ast\n",
    "\n",
    "\n",
    "\n",
    "# Add the model_name and kwargs into df_best_models\n",
    "new_row = pd.DataFrame({\n",
    "    'model': ['TAN'],  # wrap in a list to indicate a row\n",
    "    'best parameters': [\"OrderedDict({})\"] , # use OrderedDict object directly\n",
    "    'num fea': X.shape[1]\n",
    "})\n",
    "\n",
    "print(best_models.shape)\n",
    "# Concatenate the new row to the existing df_best_models DataFrame\n",
    "complete_best_models = pd.concat([new_row, best_models], ignore_index=True)\n",
    "\n",
    "print(complete_best_models.shape)\n",
    "\n",
    "print(\"model,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\")\n",
    "for index, row in complete_best_models.iloc[::-1].iterrows():\n",
    "    model_name = row['model']\n",
    "    if model_name != \"GradientBoostingClassifier\":\n",
    "        continue \n",
    "    kwargs = row['best parameters'].replace(\"OrderedDict(\", '').replace(\"})\", '}')\n",
    "    kwargs = ast.literal_eval(kwargs)\n",
    "    subset_features = np.array(features)[fea_subsets[int(row['num fea'])]] if int(row['num fea']) in fea_subsets else features\n",
    "    \n",
    "    if model_name == 'Logistic regression': \n",
    "        model = LogisticRegression(solver='newton-cholesky', **kwargs)\n",
    "    elif model_name == 'Discriminant analysis (not svd)': \n",
    "        model = LinearDiscriminantAnalysis(**kwargs)\n",
    "    elif model_name == 'Discriminant analysis (svd)': \n",
    "        model = LinearDiscriminantAnalysis(store_covariance=True, **kwargs)\n",
    "    elif model_name == 'ComplementNB': \n",
    "        model = ComplementNB(**kwargs)\n",
    "    elif model_name == 'QuadraticDiscriminantAnalysis': \n",
    "        model = QuadraticDiscriminantAnalysis(**kwargs)\n",
    "    elif model_name == 'TAN': \n",
    "        df_train = pd.concat([X_train[subset_features], y_train.rename(response_var)], axis=1)\n",
    "        estimator = TreeSearch(df_train, root_node='MentHlth')\n",
    "        dag = estimator.estimate(estimator_type='tan', class_node=response_var)\n",
    "    elif model_name == \"GradientBoostingClassifier\":\n",
    "        model = GradientBoostingClassifier()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model {model_name}\")\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)  # You can adjust n_splits as needed\n",
    "    accuracies = []\n",
    "    f1_macros = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    accuracies_per_class = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_index], y_train.iloc[test_index]\n",
    "        \n",
    "        if model_name == 'ComplementNB':\n",
    "            mmt = MinMaxScaler()\n",
    "            X_train_fold = mmt.fit_transform(X_train_fold[subset_features])\n",
    "            X_test_fold = mmt.transform(X_test_fold[subset_features])  # Apply the same scaler for test fold\n",
    "            model.fit(X_train_fold, y_train_fold)  # Fit the model on the transformed data\n",
    "            y_pred = model.predict(X_test_fold)\n",
    "        elif model_name == \"TAN\":\n",
    "            # Parameterize the model using the training data\n",
    "            model = BayesianNetwork(dag.edges())\n",
    "            model.fit(df_train, estimator=BayesianEstimator, prior_type='K2', n_jobs=-1)\n",
    "            y_pred = model.predict(X_test_fold[subset_features])\n",
    "        else:\n",
    "            model.fit(X_train_fold[subset_features], y_train_fold) \n",
    "            y_pred = model.predict(X_test_fold[subset_features])\n",
    "        \n",
    "        # Calculate the metrics\n",
    "        accuracy = accuracy_score(y_test_fold, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        matrix = confusion_matrix(y_test_fold, y_pred)\n",
    "        accuracy_per_class = matrix.diagonal() / matrix.sum(axis=1)\n",
    "        accuracies_per_class.append(accuracy_per_class)\n",
    "        \n",
    "        f1_macro = f1_score(y_test_fold, y_pred, average='macro')\n",
    "        f1_macros.append(f1_macro)\n",
    "        \n",
    "        precision = precision_score(y_test_fold, y_pred, average='macro')\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test_fold, y_pred, average='macro')\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"{model_name},{np.mean(accuracies):.03f},{\",\".join(f\"{x:.3f}\" for x in np.mean(accuracies_per_class, axis=0))},{np.mean(f1_macros):.03f},{np.mean(precisions):.03f},{np.mean(recalls):.03f}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\n",
    "TAN,0.833,0.923,0.003,0.395,0.443,0.537,0.440\n",
    "QuadraticDiscriminantAnalysis,0.793,0.846,0.000,0.574,0.442,0.426,0.473\n",
    "Logistic regression,0.689,0.701,0.154,0.685,0.436,0.437,0.513\n",
    "Discriminant analysis (svd),0.845,0.967,0.000,0.220,0.407,0.457,0.396\n",
    "Discriminant analysis (not svd),0.817,0.892,0.000,0.466,0.442,0.433,0.453\n",
    "ComplementNB,0.770,0.859,0.129,0.312,0.422,0.432,0.433\n",
    "\"\"\""
   ],
   "id": "e2065a53f8de029d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n",
      "(7, 6)\n",
      "model,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\n",
      "GradientBoostingClassifier,0.850,0.977,0.000,0.192,0.401,0.473,0.390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\\nTAN,0.833,0.923,0.003,0.395,0.443,0.537,0.440\\nQuadraticDiscriminantAnalysis,0.793,0.846,0.000,0.574,0.442,0.426,0.473\\nLogistic regression,0.689,0.701,0.154,0.685,0.436,0.437,0.513\\nDiscriminant analysis (svd),0.845,0.967,0.000,0.220,0.407,0.457,0.396\\nDiscriminant analysis (not svd),0.817,0.892,0.000,0.466,0.442,0.433,0.453\\nComplementNB,0.770,0.859,0.129,0.312,0.422,0.432,0.433\\n'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T19:15:24.664076Z",
     "start_time": "2024-11-10T19:15:15.119020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add the model_name and kwargs into df_best_models\n",
    "new_row = pd.DataFrame({\n",
    "    'model': ['TAN'],  # wrap in a list to indicate a row\n",
    "    'best parameters': [\"OrderedDict({})\"] , # use OrderedDict object directly\n",
    "    'num fea': X.shape[1]\n",
    "})\n",
    "\n",
    "print(best_models.shape)\n",
    "# Concatenate the new row to the existing df_best_models DataFrame\n",
    "complete_best_models = pd.concat([new_row, best_models], ignore_index=True)\n",
    "\n",
    "print(complete_best_models.shape)\n",
    "\n",
    "print(\"model,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\")\n",
    "\n",
    "for index, row in complete_best_models.iterrows():\n",
    "    model_name = row['model']\n",
    "    if model_name != \"GradientBoostingClassifier\":\n",
    "        continue \n",
    "    kwargs = row['best parameters'].replace(\"OrderedDict(\", '').replace(\"})\", '}')\n",
    "    kwargs = ast.literal_eval(kwargs)\n",
    "    subset_features = np.array(features)[fea_subsets[int(row['num fea'])]] if int(row['num fea']) in fea_subsets else features\n",
    "    \n",
    "    if model_name == 'Logistic regression': \n",
    "        model = LogisticRegression(solver='newton-cholesky', **kwargs)\n",
    "    elif model_name == 'Discriminant analysis (not svd)': \n",
    "        model = LinearDiscriminantAnalysis(**kwargs)\n",
    "    elif model_name == 'Discriminant analysis (svd)': \n",
    "        model = LinearDiscriminantAnalysis(store_covariance=True, **kwargs)\n",
    "    elif model_name == 'ComplementNB': \n",
    "        model = ComplementNB(**kwargs)\n",
    "    elif model_name == 'QuadraticDiscriminantAnalysis': \n",
    "        model = QuadraticDiscriminantAnalysis(**kwargs)\n",
    "    elif model_name == 'TAN': \n",
    "        pass\n",
    "    elif model_name == \"GradientBoostingClassifier\":\n",
    "        model = GradientBoostingClassifier()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)  # You can adjust n_splits as needed\n",
    "    accuracies = []\n",
    "    f1_macros = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    accuracies_per_class = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_index], y_train.iloc[test_index]\n",
    "        \n",
    "        # Apply Random Undersampling to balance the classes in the training fold\n",
    "        undersampler = RandomUnderSampler(random_state=rng)\n",
    "        X_train_fold_resampled, y_train_fold_resampled = undersampler.fit_resample(X_train_fold[subset_features], y_train_fold)\n",
    "        # X_train_fold_resampled, y_train_fold_resampled = X_train_fold[subset_features], y_train_fold\n",
    "    \n",
    "        if model_name == 'ComplementNB':\n",
    "            mmt = MinMaxScaler()\n",
    "            X_train_fold_resampled = mmt.fit_transform(X_train_fold_resampled)\n",
    "            X_test_fold = mmt.fit_transform(X_test_fold[subset_features])  # Apply the same scaler for test fold\n",
    "            model.fit(X_train_fold_resampled, y_train_fold_resampled)  # Fit the model on the transformed data\n",
    "            y_pred = model.predict(X_test_fold)  # Make predictions on the original test fold\n",
    "        elif model_name == \"TAN\":\n",
    "            # Parameterize the model using the training data\n",
    "            print(X_train_fold_resampled.__class__)\n",
    "            df_train = pd.concat([X_train_fold_resampled, y_train_fold_resampled.rename(response_var)], axis=1)\n",
    "            df_train.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            estimator = TreeSearch(df_train, root_node='MentHlth')\n",
    "            dag = estimator.estimate(estimator_type='tan', class_node=response_var)\n",
    "            model = BayesianNetwork(dag.edges())\n",
    "            model.fit(df_train, estimator=BayesianEstimator, prior_type='K2', n_jobs=-1)\n",
    "            y_pred = model.predict(data=X_test_fold[subset_features],n_jobs=-1)  # Make predictions on the original test fold\n",
    "        else:\n",
    "            model.fit(X_train_fold_resampled, y_train_fold_resampled) \n",
    "            y_pred = model.predict(X_test_fold[subset_features])  # Make predictions on the original test fold\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculate the metrics\n",
    "        accuracy = accuracy_score(y_test_fold, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        matrix = confusion_matrix(y_test_fold, y_pred)\n",
    "        accuracy_per_class = matrix.diagonal() / matrix.sum(axis=1)\n",
    "        accuracies_per_class.append(accuracy_per_class)\n",
    "        \n",
    "        f1_macro = f1_score(y_test_fold, y_pred, average='macro')\n",
    "        f1_macros.append(f1_macro)\n",
    "        \n",
    "        precision = precision_score(y_test_fold, y_pred, average='macro')\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test_fold, y_pred, average='macro')\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"\\r{model_name},{np.mean(accuracies):.03f},{\",\".join(f\"{x:.3f}\" for x in np.mean(accuracies_per_class, axis=0))},{np.mean(f1_macros):.03f},{np.mean(precisions):.03f},{np.mean(recalls):.03f}\")\n",
    "\n",
    "\n"
   ],
   "id": "9f0f0cbd085ce849",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n",
      "(7, 6)\n",
      "model,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\n",
      "GradientBoostingClassifier,0.612,0.620,0.343,0.598,0.416,0.445,0.521\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:11:30.509814Z",
     "start_time": "2024-11-10T14:11:30.491783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = \"\"\"model,accuracy,accuracy 0,accuracy 1,accuracy 2,f1_macro,precision,recall\n",
    "QuadraticDiscriminantAnalysis,0.556,0.521,0.147,0.824,0.375,0.420,0.497\n",
    "Logistic regression,0.677,0.695,0.209,0.633,0.433,0.440,0.512\n",
    "Discriminant analysis (svd),0.650,0.665,0.244,0.610,0.427,0.445,0.506\n",
    "Discriminant analysis (not svd),0.642,0.661,0.261,0.580,0.422,0.442,0.500\n",
    "ComplementNB,0.728,0.815,0.252,0.264,0.407,0.434,0.444\n",
    "\"\"\"\n",
    "\n",
    "stats = pd.read_csv(StringIO(output), delimiter=\",\")\n",
    "print(stats.columns)\n",
    "best_models = stats.loc[stats['f1_macro'].idxmax()]\n",
    "best_models"
   ],
   "id": "bf6484ad36aaa26c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model', 'accuracy', 'accuracy 0', 'accuracy 1', 'accuracy 2',\n",
      "       'f1_macro', 'precision', 'recall'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model         Logistic regression\n",
       "accuracy                    0.677\n",
       "accuracy 0                  0.695\n",
       "accuracy 1                  0.209\n",
       "accuracy 2                  0.633\n",
       "f1_macro                    0.433\n",
       "precision                    0.44\n",
       "recall                      0.512\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd8f2fb75acebfeb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
