{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T08:35:41.362704Z",
     "start_time": "2024-11-09T08:35:41.153992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "from pandas.core.indexing import check_dict_or_set_indexers\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from fss_funcs import fss\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:35:41.774636Z",
     "start_time": "2024-11-09T08:35:41.366736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"csv/outlier_filtered.csv\")\n",
    "\n",
    "response_var = 'Diabetes_012'\n",
    "features = list(df.columns)\n",
    "features.remove(response_var)\n",
    "\n",
    "print(features, response_var)\n",
    "# Pretty-print using tabulate\n",
    "df.head(1)"
   ],
   "id": "3c1badc82502073c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BMI_q_normal', 'MentHlth', 'PhysHlth_q_uniform', 'GenHlth_q_uniform', 'Age_q_uniform', 'Education_coxbox', 'Income_q_uniform', 'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex'] Diabetes_012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   BMI_q_normal  MentHlth  PhysHlth_q_uniform  GenHlth_q_uniform  \\\n",
       "0       1.60221  1.998592            0.891892                1.0   \n",
       "\n",
       "   Age_q_uniform  Education_coxbox  Income_q_uniform  Diabetes_012  HighBP  \\\n",
       "0       0.581582         -1.109347          0.117117           0.0     1.0   \n",
       "\n",
       "   HighChol  ...  Stroke  HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  \\\n",
       "0       1.0  ...     0.0                   0.0           0.0     0.0      1.0   \n",
       "\n",
       "   HvyAlcoholConsump  AnyHealthcare  NoDocbcCost  DiffWalk  Sex  \n",
       "0                0.0            1.0          0.0       1.0  0.0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI_q_normal</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth_q_uniform</th>\n",
       "      <th>GenHlth_q_uniform</th>\n",
       "      <th>Age_q_uniform</th>\n",
       "      <th>Education_coxbox</th>\n",
       "      <th>Income_q_uniform</th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>...</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.60221</td>\n",
       "      <td>1.998592</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581582</td>\n",
       "      <td>-1.109347</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:35:41.905585Z",
     "start_time": "2024-11-09T08:35:41.900367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "starting_point = [\n",
    "    'all', 'none'\n",
    "]\n",
    "search_organization = [\n",
    "    'backward', 'forward'  # , 'stepwise', 'metaheuristic'\n",
    "]\n",
    "\"\"\"\"\n",
    "Univariate:\n",
    "    Parametric methods:\n",
    "        Discrete predictors:\n",
    "            Mutual information Blanco et al. (2005)\n",
    "            Gain ratio Hall and Smith (1998)\n",
    "            Symmetrical uncertainty Hall (1999)\n",
    "            Chi-squared Forman (2003)\n",
    "            Odds ratio Mladenic and Grobelnik (1999)\n",
    "            Bi-normal separation Forman (2003\n",
    "        Continuous predictors:\n",
    "            t-test family Jafari and Azuaje (2006)\n",
    "            ANOVA Jafari and Azuaje (2006)\n",
    "    Model-free methods:\n",
    "        Threshold number of misclassification (TNoM) Ben-dor et al. (2000)\n",
    "        P-metric Slonim et al. (2000)\n",
    "        Mann-Whitney test Thomas et al. (2001)\n",
    "        Kruskal-Wallis test Lan and Vucetic (2011)\n",
    "        Between-groups to within-groups sum of squares Dudoit et al. (2002)\n",
    "        Scores based on estimating density functions Inza et al. (2004)\n",
    "Multivariate:\n",
    "    RELIEF Kira and Rendell (1992)\n",
    "    Correlation-based feature selection Hall (1999)\n",
    "    Conditional mutual information Fleuret (2004)\n",
    "\"\"\"\n",
    "uni_filter_options = [\n",
    "    \"f_classif\",\"mutual_information\"\n",
    "]\n",
    "multi_filter_options = [\n",
    "    'multivariate_cmi'\n",
    "]\n",
    "\"\"\"\n",
    "Deterministic heuristics:\n",
    "    Sequential feature selection Fu (1968)\n",
    "    Sequential forward feature selection Fu (1968)\n",
    "    Sequential backward elimination Marill and Green (1963)\n",
    "    Greedy hill climbing John et al. (1994)\n",
    "    Best first Xu et al. (1988)\n",
    "    Plus-L-Minus-r algorithm Stearns (1976)\n",
    "    Floating search selection Pudil et al. (1994)\n",
    "    Tabu search Zhang and Sun (2002)\n",
    "    Branch and bound Lawler and Wood (1966)\n",
    "Non-deterministic heuristics:\n",
    "    Single-solution metaheuristics:\n",
    "        Simulated annealing Doak (1992)\n",
    "        Las Vegas algorithm Liu and Motoda (1998)\n",
    "        Greedy randomized adaptive search procedure Bermejo et al. (2011)\n",
    "        Variable neighborhood search Garcia-Torres et al. (2005)\n",
    "    Population-based metaheuristics:\n",
    "        Scatter search Garcia-Lopez et al. (2006)\n",
    "        Ant colony optimization Al-An (2005)\n",
    "        Particle swarm optimization Lin et al. (2008)\n",
    "        Evolutionary algorithms:\n",
    "            Genetic algorithms Siedlecki and Sklansky (1989)\n",
    "            Estimation of distribution algorithms Inza et al. (2000)\n",
    "            Differential evolution Khushaba et al. (2008)\n",
    "            Genetic programming Muni et al. (2004)\n",
    "            Evolution strategies Vatolkin et al. (2009)\n",
    "\"\"\"\n",
    "wrapper_options = [\n",
    "    'sequential_feature_selection',\n",
    "]\n",
    "stopping_criterion = [\n",
    "    # 'performance_plateau',\n",
    "    'limit_fea_8', 'limit_fea_10', 'limit_fea_12', 'limit_fea_14', 'limit_fea_16'\n",
    "]\n",
    "wrapper_models = [\n",
    "    LogisticRegression(random_state=1, max_iter=1000),\n",
    "    MLPClassifier(solver='adam', alpha=1e-5,\n",
    "                  hidden_layer_sizes=(32, 32), random_state=1, max_iter=1000, early_stopping=True),\n",
    "    AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=1),\n",
    "]"
   ],
   "id": "187392a801ce8fea",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:14:05.840918Z",
     "start_time": "2024-11-07T16:26:06.696173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluator = \"wrapper_filter\"\n",
    "print(\n",
    "    f\"start,end,direction,subevaluator,model,{str(features)[1:-1]}\".replace(\"'\",\"\"))\n",
    "subdf = df.sample(frac=0.2, random_state=1)\n",
    "\n",
    "for subevaluator in wrapper_options:\n",
    "    start = \"all\"\n",
    "    for direction in search_organization:\n",
    "        if (start == 'none' and direction == 'backward') or (start == 'all' and direction == 'forward'):\n",
    "            continue\n",
    "        for end in stopping_criterion:\n",
    "                for model in [\n",
    "                            LogisticRegression(random_state=1, max_iter=1000),\n",
    "                            MLPClassifier(solver='adam', alpha=1e-5,\n",
    "                                          hidden_layer_sizes=(32, 32), random_state=1, max_iter=1000, early_stopping=True),\n",
    "                            AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=1),\n",
    "                        ]:\n",
    "                    print(f\"Evaluating {model.__class__}\", end=\"\")\n",
    "                    \n",
    "                    fs = fss(start, end, direction, subevaluator, model=model, df=df, features=features,\n",
    "                             target=response_var)\n",
    "                    if len(fs) > 1:\n",
    "                        model_srt = str(model).replace(\"alpha=1e-05, early_stopping=True, \", \"\").replace(\", random_state=1\", \"\").replace(\" \", \"\").replace(\"\\n\", \"\").replace(\",\", \"|\")\n",
    "                        print(\n",
    "                            f\"\\r{start},{end},{direction},{evaluator},{model_srt},{np.array2string(fs.astype(int), separator=',')[1:-1]}\")"
   ],
   "id": "6a4a5d7ee27fa330",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start,end,direction,subevaluator,model,BMI_q_normal, MentHlth, PhysHlth_q_uniform, GenHlth_q_uniform, Age_q_uniform, Education_coxbox, Income_q_uniform, HighBP, HighChol, CholCheck, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, DiffWalk, Sex\n",
      "all,limit_fea_8,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,1,0,0,0,0\n",
      "all,limit_fea_8,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,0,0,1,1,0,0,1,0,1,0,0,1,0,0,0,1,1,0,0,0\n",
      "all,limit_fea_8,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,0,1,0,0,0,1\n",
      "all,limit_fea_10,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,1,0,0,1,1\n",
      "all,limit_fea_10,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,0,0,1,1,0,0,1,0,1,1,0,1,1,0,0,1,1,0,0,0\n",
      "all,limit_fea_10,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,0,1,1,1,0,0,1,1,0,0,0,1,0,0,0,1\n",
      "all,limit_fea_12,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,0,1,0,0,1,1\n",
      "all,limit_fea_12,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,0,0,1,1,0,0,1,1,1,1,0,1,1,0,0,1,1,0,1,0\n",
      "all,limit_fea_12,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,0,1,1,0,0,1\n",
      "all,limit_fea_14,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,0,1,0,0,1,1\n",
      "all,limit_fea_14,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,1,0,1,1,0,0,1,1,1,1,0,1,1,0,1,1,1,0,1,0\n",
      "all,limit_fea_14,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,0,1,1\n",
      "all,limit_fea_16,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,1,1\n",
      "all,limit_fea_16,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,1,0,1,0\n",
      "all,limit_fea_16,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,0,1,1\n",
      "none,limit_fea_8,forward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,0,1,1,0,0,0,1,0,0,0,1,0,0,1,0\n",
      "Evaluating <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 20\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[0;32m     13\u001B[0m             LogisticRegression(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m),\n\u001B[0;32m     14\u001B[0m             MLPClassifier(solver\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m,\n\u001B[0;32m     15\u001B[0m                           hidden_layer_sizes\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m32\u001B[39m), random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, early_stopping\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[0;32m     16\u001B[0m             AdaBoostClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m),\n\u001B[0;32m     17\u001B[0m         ]:\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 20\u001B[0m     fs \u001B[38;5;241m=\u001B[39m fss(start, end, direction, subevaluator, model\u001B[38;5;241m=\u001B[39mmodel, df\u001B[38;5;241m=\u001B[39mdf, features\u001B[38;5;241m=\u001B[39mfeatures,\n\u001B[0;32m     21\u001B[0m              target\u001B[38;5;241m=\u001B[39mresponse_var)\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     23\u001B[0m         model_srt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(model)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malpha=1e-05, early_stopping=True, \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, random_state=1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MLPracticals\\fss_funcs.py:259\u001B[0m, in \u001B[0;36mfss\u001B[1;34m(start_fs, end_condition, dir, eval_strategy, df, features, target, model)\u001B[0m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfss\u001B[39m(start_fs, end_condition, \u001B[38;5;28mdir\u001B[39m, eval_strategy, df, features, target, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m eval_strategy \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msequential_feature_selection\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 259\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m get_SFS(start_fs, end_condition, \u001B[38;5;28mdir\u001B[39m, model, df\u001B[38;5;241m=\u001B[39mdf, features\u001B[38;5;241m=\u001B[39mfeatures, target\u001B[38;5;241m=\u001B[39mtarget)\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m eval_strategy \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrasp\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    261\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluator unimplemented: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m eval_strategy)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MLPracticals\\fss_funcs.py:51\u001B[0m, in \u001B[0;36mget_SFS\u001B[1;34m(start, end, direction, model, df, features, target)\u001B[0m\n\u001B[0;32m     49\u001B[0m X \u001B[38;5;241m=\u001B[39m df[features]\n\u001B[0;32m     50\u001B[0m y \u001B[38;5;241m=\u001B[39m df[target]\n\u001B[1;32m---> 51\u001B[0m sfs\u001B[38;5;241m.\u001B[39mfit(X, y)\n\u001B[0;32m     52\u001B[0m result \u001B[38;5;241m=\u001B[39m sfs\u001B[38;5;241m.\u001B[39mget_support()\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (np\u001B[38;5;241m.\u001B[39msum(result) \u001B[38;5;241m==\u001B[39m n_fea)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:252\u001B[0m, in \u001B[0;36mSequentialFeatureSelector.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    250\u001B[0m is_auto_select \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtol \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_to_select \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_iterations):\n\u001B[1;32m--> 252\u001B[0m     new_feature_idx, new_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_best_new_feature_score(\n\u001B[0;32m    253\u001B[0m         cloned_estimator, X, y, cv, current_mask\n\u001B[0;32m    254\u001B[0m     )\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_auto_select \u001B[38;5;129;01mand\u001B[39;00m ((new_score \u001B[38;5;241m-\u001B[39m old_score) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtol):\n\u001B[0;32m    256\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:283\u001B[0m, in \u001B[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001B[1;34m(self, estimator, X, y, cv, current_mask)\u001B[0m\n\u001B[0;32m    281\u001B[0m         candidate_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m~\u001B[39mcandidate_mask\n\u001B[0;32m    282\u001B[0m     X_new \u001B[38;5;241m=\u001B[39m X[:, candidate_mask]\n\u001B[1;32m--> 283\u001B[0m     scores[feature_idx] \u001B[38;5;241m=\u001B[39m cross_val_score(\n\u001B[0;32m    284\u001B[0m         estimator,\n\u001B[0;32m    285\u001B[0m         X_new,\n\u001B[0;32m    286\u001B[0m         y,\n\u001B[0;32m    287\u001B[0m         cv\u001B[38;5;241m=\u001B[39mcv,\n\u001B[0;32m    288\u001B[0m         scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring,\n\u001B[0;32m    289\u001B[0m         n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs,\n\u001B[0;32m    290\u001B[0m     )\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m    291\u001B[0m new_feature_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(scores, key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m feature_idx: scores[feature_idx])\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001B[0m, in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    709\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[0;32m    710\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m--> 712\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m cross_validate(\n\u001B[0;32m    713\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[0;32m    714\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m    715\u001B[0m     y\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m    716\u001B[0m     groups\u001B[38;5;241m=\u001B[39mgroups,\n\u001B[0;32m    717\u001B[0m     scoring\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: scorer},\n\u001B[0;32m    718\u001B[0m     cv\u001B[38;5;241m=\u001B[39mcv,\n\u001B[0;32m    719\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39mn_jobs,\n\u001B[0;32m    720\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m    721\u001B[0m     fit_params\u001B[38;5;241m=\u001B[39mfit_params,\n\u001B[0;32m    722\u001B[0m     params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[0;32m    723\u001B[0m     pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch,\n\u001B[0;32m    724\u001B[0m     error_score\u001B[38;5;241m=\u001B[39merror_score,\n\u001B[0;32m    725\u001B[0m )\n\u001B[0;32m    726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:423\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[0;32m    420\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    421\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    422\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 423\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[0;32m    424\u001B[0m     delayed(_fit_and_score)(\n\u001B[0;32m    425\u001B[0m         clone(estimator),\n\u001B[0;32m    426\u001B[0m         X,\n\u001B[0;32m    427\u001B[0m         y,\n\u001B[0;32m    428\u001B[0m         scorer\u001B[38;5;241m=\u001B[39mscorers,\n\u001B[0;32m    429\u001B[0m         train\u001B[38;5;241m=\u001B[39mtrain,\n\u001B[0;32m    430\u001B[0m         test\u001B[38;5;241m=\u001B[39mtest,\n\u001B[0;32m    431\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m    432\u001B[0m         parameters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    433\u001B[0m         fit_params\u001B[38;5;241m=\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mfit,\n\u001B[0;32m    434\u001B[0m         score_params\u001B[38;5;241m=\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39mscorer\u001B[38;5;241m.\u001B[39mscore,\n\u001B[0;32m    435\u001B[0m         return_train_score\u001B[38;5;241m=\u001B[39mreturn_train_score,\n\u001B[0;32m    436\u001B[0m         return_times\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    437\u001B[0m         return_estimator\u001B[38;5;241m=\u001B[39mreturn_estimator,\n\u001B[0;32m    438\u001B[0m         error_score\u001B[38;5;241m=\u001B[39merror_score,\n\u001B[0;32m    439\u001B[0m     )\n\u001B[0;32m    440\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m indices\n\u001B[0;32m    441\u001B[0m )\n\u001B[0;32m    443\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    445\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    446\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    447\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     69\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     70\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     71\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     73\u001B[0m )\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1762\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T19:09:53.625954Z",
     "start_time": "2024-11-09T08:36:16.635177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluator = \"wrapper_filter\"\n",
    "print(\n",
    "    f\"start,end,direction,subevaluator,model,{str(features)[1:-1]}\".replace(\"'\",\"\"))\n",
    "subdf = df.sample(frac=0.2, random_state=1)\n",
    "\n",
    "for subevaluator in wrapper_options:\n",
    "    start = \"none\"\n",
    "    for direction in search_organization:\n",
    "        if (start == 'none' and direction == 'backward') or (start == 'all' and direction == 'forward'):\n",
    "            continue\n",
    "        for end in stopping_criterion:\n",
    "                for model in [\n",
    "                            LogisticRegression(random_state=1, max_iter=1000),\n",
    "                            MLPClassifier(solver='adam', alpha=1e-5,\n",
    "                                          hidden_layer_sizes=(32, 32), random_state=1, max_iter=1000, early_stopping=True),\n",
    "                            AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=1),\n",
    "                        ]:\n",
    "                    print(f\"Evaluating {model.__class__}\", end=\"\")\n",
    "                    \n",
    "                    fs = fss(start, end, direction, subevaluator, model=model, df=df, features=features,\n",
    "                             target=response_var)\n",
    "                    if len(fs) > 1:\n",
    "                        model_srt = str(model).replace(\"alpha=1e-05, early_stopping=True, \", \"\").replace(\", random_state=1\", \"\").replace(\" \", \"\").replace(\"\\n\", \"\").replace(\",\", \"|\")\n",
    "                        print(\n",
    "                            f\"\\r{start},{end},{direction},{evaluator},{model_srt},{np.array2string(fs.astype(int), separator=',')[1:-1]}\")"
   ],
   "id": "d6657322afcc882e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start,end,direction,subevaluator,model,BMI_q_normal, MentHlth, PhysHlth_q_uniform, GenHlth_q_uniform, Age_q_uniform, Education_coxbox, Income_q_uniform, HighBP, HighChol, CholCheck, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, DiffWalk, Sex\n",
      "None,limit_fea_8,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,1,0,0,0,0\n",
      "None,limit_fea_8,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,0,0,1,1,0,0,1,0,1,0,0,1,0,0,0,1,1,0,0,0\n",
      "None,limit_fea_8,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,0,1,0,0,0,1\n",
      "None,limit_fea_10,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,1,0,0,1,1\n",
      "None,limit_fea_10,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,0,0,1,1,0,0,1,0,1,1,0,1,1,0,0,1,1,0,0,0\n",
      "None,limit_fea_10,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,0,1,1,1,0,0,1,1,0,0,0,1,0,0,0,1\n",
      "None,limit_fea_12,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,0,1,0,0,1,1\n",
      "None,limit_fea_12,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,0,0,1,1,0,0,1,1,1,1,0,1,1,0,0,1,1,0,1,0\n",
      "None,limit_fea_12,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,0,1,1,0,0,1\n",
      "None,limit_fea_14,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,0,1,0,0,1,1\n",
      "None,limit_fea_14,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,1,0,1,1,0,0,1,1,1,1,0,1,1,0,1,1,1,0,1,0\n",
      "None,limit_fea_14,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,0,1,1\n",
      "None,limit_fea_16,backward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,1,1\n",
      "None,limit_fea_16,backward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,1,0,1,0\n",
      "None,limit_fea_16,backward,wrapper_filter,AdaBoostClassifier(random_state=1),1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,0,1,1\n",
      "None,limit_fea_8,forward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,0,1,1,0,0,0,1,0,0,0,1,0,0,1,0\n",
      "None,limit_fea_8,forward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,0,0,1,1,0,0,1,1,0,0,0,1,1,0,0,0,0,0,0,1\n",
      "None,limit_fea_8,forward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,0,0,1,1,1,0,0,1,0,0,0,1,0,0,0,0\n",
      "None,limit_fea_10,forward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,1,1,1,1,0,0,1,0,0,0,1,0,0,1,0\n",
      "None,limit_fea_10,forward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,0,1,1,1,0,0,1,1,0,1,0,1,1,0,0,0,0,0,0,1\n",
      "None,limit_fea_10,forward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,0,1,0,0,0,0\n",
      "None,limit_fea_12,forward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,0,1,0,0,1,1\n",
      "None,limit_fea_12,forward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,1,1,1,1,0,0,1,1,0,1,1,1,1,0,0,0,0,0,0,1\n",
      "None,limit_fea_12,forward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,0,1,1,1,1,1,1,1,0,1,1,0,0,0,1,0,0,0,1\n",
      "None,limit_fea_14,forward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,0,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,0,1,1\n",
      "None,limit_fea_14,forward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,1,1,1,1,0,1,1,1,0,1,1,1,1,0,0,1,0,0,0,1\n",
      "None,limit_fea_14,forward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,1,1,1,1,1,1,1,1,0,1,1,1,0,0,1,0,0,0,1\n",
      "None,limit_fea_16,forward,wrapper_filter,LogisticRegression(max_iter=1000),1,0,1,1,1,1,1,1,1,1,0,1,1,1,0,0,1,1,0,1,1\n",
      "None,limit_fea_16,forward,wrapper_filter,MLPClassifier(hidden_layer_sizes=(32|32)|max_iter=1000),1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,0,0,1\n",
      "None,limit_fea_16,forward,wrapper_filter,AdaBoostClassifier(random_state=1),1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:44:15.007003Z",
     "start_time": "2024-11-07T14:26:38.453422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "evaluator = \"multi_filter\"\n",
    "print(\n",
    "    f\"start,end,direction,subevaluator,model,{str(features)[1:-1]}\".replace(\"'\",\"\"))\n",
    "\n",
    "for start in starting_point:\n",
    "    for direction in search_organization:\n",
    "        if (start == 'none' and direction == 'backward') or (start == 'all' and direction == 'forward'):\n",
    "            continue\n",
    "\n",
    "        for end in stopping_criterion:\n",
    "                for subevaluator in multi_filter_options:\n",
    "                    fs = fss(start, end, direction, subevaluator, df=df, features=features, target=response_var)\n",
    "                    if len(fs) > 1:\n",
    "                        print(\n",
    "                            f\"{start},{end},{direction},{evaluator},{subevaluator},{np.array2string(fs.astype(int), separator=',')[1:-1]}\")"
   ],
   "id": "b15f5934ac769cde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start,end,direction,subevaluator,model,BMI_q_normal, MentHlth, PhysHlth_q_uniform, GenHlth_q_uniform, Age_q_uniform, Education_coxbox, Income_q_uniform, HighBP, HighChol, CholCheck, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, DiffWalk, Sex\n",
      "all,limit_fea_8,backward,multi_filter,multivariate_cmi,1,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,0,1,0\n",
      "all,limit_fea_10,backward,multi_filter,multivariate_cmi,1,0,1,1,1,1,1,1,1,0,0,0,1,0,0,0,0,0,0,1,0\n",
      "all,limit_fea_12,backward,multi_filter,multivariate_cmi,1,0,1,1,1,1,1,1,1,0,0,1,1,1,0,0,0,0,0,1,0\n",
      "all,limit_fea_14,backward,multi_filter,multivariate_cmi,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,1,0\n",
      "all,limit_fea_16,backward,multi_filter,multivariate_cmi,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,1,0\n",
      "none,limit_fea_8,forward,multi_filter,multivariate_cmi,1,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,0,0,0,1,0\n",
      "none,limit_fea_10,forward,multi_filter,multivariate_cmi,1,0,0,1,1,1,1,1,1,1,0,0,1,0,0,0,0,0,0,1,0\n",
      "none,limit_fea_12,forward,multi_filter,multivariate_cmi,1,0,0,1,1,1,1,1,1,1,0,1,1,0,0,0,1,0,0,1,0\n",
      "none,limit_fea_14,forward,multi_filter,multivariate_cmi,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,1,0,0,1,0\n",
      "none,limit_fea_16,forward,multi_filter,multivariate_cmi,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,1,0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T13:25:05.991301Z",
     "start_time": "2024-11-07T13:22:44.521324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluator = \"uni_filter\"\n",
    "print(\n",
    "    f\"start,end,direction,subevaluator,model,{str(features)[1:-1]}\".replace(\"'\",\"\"))\n",
    "\n",
    "for start in starting_point:\n",
    "    for direction in search_organization:\n",
    "        if (start == 'none' and direction == 'backward') or (start == 'all' and direction == 'forward'):\n",
    "            continue\n",
    "\n",
    "        for end in stopping_criterion:\n",
    "                for subevaluator in uni_filter_options:\n",
    "                    fs = fss(start, end, direction, subevaluator, df=df, features=features, target=response_var)\n",
    "                    if len(fs) > 1:\n",
    "                        print(\n",
    "                            f\"{start},{end},{direction},{evaluator},{subevaluator},{np.array2string(fs.astype(int), separator=',')[1:-1]}\")"
   ],
   "id": "a16f9618285b206d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start,end,direction,subevaluator,model,BMI_q_normal, MentHlth, PhysHlth_q_uniform, GenHlth_q_uniform, Age_q_uniform, Education_coxbox, Income_q_uniform, HighBP, HighChol, CholCheck, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, DiffWalk, Sex\n",
      "none,limit_fea_8,forward,uni_filter,f_classif,1,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,0,0,0,1,0\n",
      "none,limit_fea_8,forward,uni_filter,mutual_information,0,0,0,1,0,0,0,1,1,1,0,0,0,1,1,1,0,1,0,0,0\n",
      "none,limit_fea_10,forward,uni_filter,f_classif,1,0,1,1,1,1,1,1,1,0,0,0,1,0,0,0,0,0,0,1,0\n",
      "none,limit_fea_10,forward,uni_filter,mutual_information,1,0,0,1,0,0,1,1,1,1,0,0,0,1,1,1,0,1,0,0,0\n",
      "none,limit_fea_12,forward,uni_filter,f_classif,1,0,1,1,1,1,1,1,1,0,0,1,1,1,0,0,0,0,0,1,0\n",
      "none,limit_fea_12,forward,uni_filter,mutual_information,1,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,0,1,0,0,0\n",
      "none,limit_fea_14,forward,uni_filter,f_classif,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,1,0\n",
      "none,limit_fea_14,forward,uni_filter,mutual_information,1,0,0,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,0,1,0\n",
      "none,limit_fea_16,forward,uni_filter,f_classif,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,1,0\n",
      "none,limit_fea_16,forward,uni_filter,mutual_information,1,0,0,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,0,1,1\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T19:33:06.887029Z",
     "start_time": "2024-11-09T19:33:06.878045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fss_stats = pd.read_csv(\"./csv/fss.csv\")\n",
    "\n",
    "uni_df = fss_stats[fss_stats['subevaluator'] == \"uni_filter\"]\n",
    "multi_df = fss_stats[fss_stats['subevaluator'] == \"multi_filter\"]\n",
    "wrapper_df = fss_stats[fss_stats['subevaluator'] == \"wrapper_filter\"]"
   ],
   "id": "1a0aa0186542d747",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T19:33:07.198713Z",
     "start_time": "2024-11-09T19:33:07.180609Z"
    }
   },
   "cell_type": "code",
   "source": "uni_df.loc[uni_df['model'] == 'f_classif', uni_df.columns[5:]] *= 1.05 # Tiebreaker",
   "id": "29659bbf16d65c5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T19:33:07.680870Z",
     "start_time": "2024-11-09T19:33:07.660905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Features kept in univariate feature selection\")\n",
    "for i in [8,10,12,14,16]:\n",
    "    rows = uni_df[uni_df['end'] == 'limit_fea_' + str(i)].iloc[:, 5:]\n",
    "    print(f\"K={i:02d} -> {sorted([uni_df.columns.get_loc(col)-5 for col in rows.mean(axis=0).nlargest(i).index])}\")"
   ],
   "id": "1df5c53adb3dba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features kept in univariate feature selection\n",
      "K=08 -> [0, 3, 4, 6, 7, 8, 12, 19]\n",
      "K=10 -> [0, 2, 3, 4, 5, 6, 7, 8, 12, 19]\n",
      "K=12 -> [0, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 19]\n",
      "K=14 -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19]\n",
      "K=16 -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 19]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T19:33:08.292597Z",
     "start_time": "2024-11-09T19:33:08.280280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Features kept in multivariate feature selection\")\n",
    "for i in [8,10,12,14,16]:\n",
    "    rows = multi_df[multi_df['end'] == 'limit_fea_' + str(i)].iloc[:, 5:]\n",
    "    print(f\"K={i:02d} -> {sorted([multi_df.columns.get_loc(col)-5 for col in rows.mean(axis=0).nlargest(i).index])}\")"
   ],
   "id": "4099c885c5ff711b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features kept in multivariate feature selection\n",
      "K=08 -> [0, 2, 3, 4, 6, 7, 8, 19]\n",
      "K=10 -> [0, 2, 3, 4, 5, 6, 7, 8, 12, 19]\n",
      "K=12 -> [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 19]\n",
      "K=14 -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19]\n",
      "K=16 -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 19]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T19:33:08.797155Z",
     "start_time": "2024-11-09T19:33:08.785337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Features kept in wrapper feature selection\")\n",
    "for i in [8,10,12,14,16]:\n",
    "    rows = wrapper_df[wrapper_df['end'] == 'limit_fea_' + str(i)].iloc[:, 5:]\n",
    "    print(f\"K={i:02d} -> {sorted([wrapper_df.columns.get_loc(col)-5 for col in rows.mean(axis=0).nlargest(i).index])}\")"
   ],
   "id": "375bcdc9010abac8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features kept in wrapper feature selection\n",
      "K=08 -> [0, 3, 4, 6, 7, 8, 12, 16]\n",
      "K=10 -> [0, 3, 4, 6, 7, 8, 9, 12, 16, 20]\n",
      "K=12 -> [0, 3, 4, 6, 7, 8, 9, 11, 12, 16, 17, 19]\n",
      "K=14 -> [0, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19]\n",
      "K=16 -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:34:25.061487Z",
     "start_time": "2024-11-10T17:34:25.052565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "[17] # Wrapper\n",
    "[16] # Multivariate\n",
    "[15] #Univariate\n",
    "\n",
    "[18,14,20] # None chose"
   ],
   "id": "aef43cf59338c2fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "59976971b1a840f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
